{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Decision Tree: Classifying the Titanic Dataset Without Machine Learning Libraries\n\n ### 1. Introduction\n\n### 2. Preprocessing\n\n### 3. Impurity Measure\n\n### 4. Splitting Data\n\n### 5. Getting Full Tree\n\n### 6. Recursive partitioning\n\n### 7. Making Predictions With Pruned Tree\n\n### 8. Submission\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# 1.Introduction \n\n![](http://)This is my attempt at creating a decision tree without using only numpy and pandas libraries. I did not reference other people's code or approaches; rather I watched the StatQuest video on Decision Trees (https://www.youtube.com/watch?v=7VeUPuFGJHk) to understand the algorithm and took my own approach to code it. This was simply meant as a challenge and a learning exercise for me.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport itertools\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n#train_data.head(10)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-13T18:50:50.469173Z","iopub.execute_input":"2021-10-13T18:50:50.469803Z","iopub.status.idle":"2021-10-13T18:50:50.489546Z","shell.execute_reply.started":"2021-10-13T18:50:50.469765Z","shell.execute_reply":"2021-10-13T18:50:50.488371Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2.Preprocessing \nThe age variable has missing data but all of the other numeric columns are fine. An approach is to group data by another variable and find the average age for each group and impute the average into the missing values. I will take group by the title of each person since people with similar title may have similar ages.","metadata":{}},{"cell_type":"code","source":"train_data[\"Name\"] = train_data[\"Name\"].str.split(',').str[1]\ntrain_data[\"Name\"] = train_data[\"Name\"].str.split('.').str[0]\ntrain_data[\"Name\"] = train_data[\"Name\"].str.strip()\nx = train_data.groupby('Name').agg(['count']).index.get_level_values('Name')\nx","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-10-13T18:50:50.491484Z","iopub.execute_input":"2021-10-13T18:50:50.491760Z","iopub.status.idle":"2021-10-13T18:50:50.536138Z","shell.execute_reply.started":"2021-10-13T18:50:50.491732Z","shell.execute_reply":"2021-10-13T18:50:50.535110Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Index(['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Master',\n       'Miss', 'Mlle', 'Mme', 'Mr', 'Mrs', 'Ms', 'Rev', 'Sir', 'the Countess'],\n      dtype='object', name='Name')"},"metadata":{}}]},{"cell_type":"code","source":"train_data[\"Age\"] = train_data.groupby(\"Name\").transform(lambda x: x.fillna(x.mean()))['Age']\n#changing sex to be 0 or 1 for female & male\ntrain_data['Sex'].replace({'female':0,'male':1},inplace=True)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:50.537616Z","iopub.execute_input":"2021-10-13T18:50:50.538047Z","iopub.status.idle":"2021-10-13T18:50:50.620045Z","shell.execute_reply.started":"2021-10-13T18:50:50.538004Z","shell.execute_reply":"2021-10-13T18:50:50.619148Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n0            1         0       3    Mr    1  22.0      1      0   \n1            2         1       1   Mrs    0  38.0      1      0   \n2            3         1       3  Miss    0  26.0      0      0   \n3            4         1       1   Mrs    0  35.0      1      0   \n4            5         0       3    Mr    1  35.0      0      0   \n\n             Ticket     Fare Cabin Embarked  \n0         A/5 21171   7.2500   NaN        S  \n1          PC 17599  71.2833   C85        C  \n2  STON/O2. 3101282   7.9250   NaN        S  \n3            113803  53.1000  C123        S  \n4            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Mrs</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Miss</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Mrs</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data_tree = train_data.iloc[:,[False,False,True, False,True,True,True,True,False,True,False,False]]\ntrain_labels_tree = train_data.iloc[:,1]\ntrain_data_tree.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:50.621272Z","iopub.execute_input":"2021-10-13T18:50:50.621570Z","iopub.status.idle":"2021-10-13T18:50:50.655229Z","shell.execute_reply.started":"2021-10-13T18:50:50.621544Z","shell.execute_reply":"2021-10-13T18:50:50.654115Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"           Pclass         Sex         Age       SibSp       Parch        Fare\ncount  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\nmean     2.308642    0.647587   29.754659    0.523008    0.381594   32.204208\nstd      0.836071    0.477990   13.277179    1.102743    0.806057   49.693429\nmin      1.000000    0.000000    0.420000    0.000000    0.000000    0.000000\n25%      2.000000    0.000000   21.773973    0.000000    0.000000    7.910400\n50%      3.000000    1.000000   30.000000    0.000000    0.000000   14.454200\n75%      3.000000    1.000000   35.898148    1.000000    0.000000   31.000000\nmax      3.000000    1.000000   80.000000    8.000000    6.000000  512.329200","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.308642</td>\n      <td>0.647587</td>\n      <td>29.754659</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.836071</td>\n      <td>0.477990</td>\n      <td>13.277179</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>21.773973</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>35.898148</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"For the categorical variables, I'm transforming the columns into columns of dummy variables.","metadata":{}},{"cell_type":"code","source":"#Need to create dummy variable columns for the Pclass variable. The other variables are either binary or numeric\ntrain_data_tree_dummy = pd.concat([train_data_tree,pd.get_dummies(train_data_tree['Pclass'], prefix='Pclass')],axis=1)\n\ntrain_data_tree_dummy.drop([\"Pclass\"],axis=1,inplace=True)\nsib_sp = pd.cut(train_data_tree_dummy[\"SibSp\"], 3,labels=[0,1,2]).tolist()\nparch = pd.cut(train_data_tree_dummy[\"Parch\"], 3,labels=[0,1,2]).tolist()\n\ntrain_data_tree_dummy.drop([\"Parch\"],axis=1,inplace=True)\ntrain_data_tree_dummy[\"SibSp2\"] = np.where(train_data_tree_dummy.SibSp==0,0,1)\ntrain_data_tree_dummy.drop([\"SibSp\"],axis=1,inplace=True)\n\n\n\ntrain_data_tree_dummy.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:50.658035Z","iopub.execute_input":"2021-10-13T18:50:50.658304Z","iopub.status.idle":"2021-10-13T18:50:50.708465Z","shell.execute_reply.started":"2021-10-13T18:50:50.658277Z","shell.execute_reply":"2021-10-13T18:50:50.707366Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"              Sex         Age        Fare    Pclass_1    Pclass_2    Pclass_3  \\\ncount  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \nmean     0.647587   29.754659   32.204208    0.242424    0.206510    0.551066   \nstd      0.477990   13.277179   49.693429    0.428790    0.405028    0.497665   \nmin      0.000000    0.420000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000   21.773973    7.910400    0.000000    0.000000    0.000000   \n50%      1.000000   30.000000   14.454200    0.000000    0.000000    1.000000   \n75%      1.000000   35.898148   31.000000    0.000000    0.000000    1.000000   \nmax      1.000000   80.000000  512.329200    1.000000    1.000000    1.000000   \n\n           SibSp2  \ncount  891.000000  \nmean     0.317621  \nstd      0.465813  \nmin      0.000000  \n25%      0.000000  \n50%      0.000000  \n75%      1.000000  \nmax      1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>SibSp2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.647587</td>\n      <td>29.754659</td>\n      <td>32.204208</td>\n      <td>0.242424</td>\n      <td>0.206510</td>\n      <td>0.551066</td>\n      <td>0.317621</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.477990</td>\n      <td>13.277179</td>\n      <td>49.693429</td>\n      <td>0.428790</td>\n      <td>0.405028</td>\n      <td>0.497665</td>\n      <td>0.465813</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>21.773973</td>\n      <td>7.910400</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>30.000000</td>\n      <td>14.454200</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>35.898148</td>\n      <td>31.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>512.329200</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3.Impurity \nFor the measure of impurity, I'm using Gini. Lower values indicate better splits, so this function calculates Gini for each column to determine the best variable to split.","metadata":{}},{"cell_type":"code","source":"def gini_calc(train,labels):\n    gini_list = []\n    numeric_indices = []\n    numeric_best_split = []\n    counter = -1\n    for i in train:\n        counter +=1\n        if train[i].dtype == \"int64\" or train[i].dtype ==\"uint8\":\n            split_1 = train[train[i] == 0]\n            split_2 = train[train[i] == 1]\n            split_1_index = split_1.index\n            split_2_index = split_2.index\n            labels_split_1 = labels[split_1_index]\n            labels_split_2 = labels[split_2_index]\n\n            val1 = (labels_split_1==0).sum()\n            val2 = (labels_split_1==1).sum()\n            val3 = (labels_split_2==0).sum()\n            val4 = (labels_split_2==1).sum()\n\n            gini_one = 1 - (val1/(val1+val2))**2 - (val2/(val1+val2))**2\n            gini_two = 1 - (val3/(val3+val4))**2 - (val4/(val3+val4))**2                \n            weighted_gini = (gini_one * (val1 + val2)/(len(train_labels_tree))) + (gini_two * (val3 + val4)/(len(train_labels_tree))) \n            gini_list.append(weighted_gini)\n        elif train[i].dtype == \"float64\":\n            numeric_indices.append(counter)\n            numeric_gini_lst = []\n            numeric_vals = np.array(train.sort_values([i])[i].reset_index(drop=True))\n            averages = (numeric_vals[0:len(numeric_vals)-1] + numeric_vals[1:len(numeric_vals)])/2\n            zeros = np.zeros(len(labels))\n            ones = zeros + 1 \n            \n            for val in averages:\n                vals_array = ones*val\n                split_1 = train[train[i] <= vals_array]\n                split_2 = train[train[i] >= vals_array]\n                split_1_index = split_1.index\n                split_2_index = split_2.index\n                labels_split_1 = labels[split_1_index]\n                labels_split_2 = labels[split_2_index]\n                \n                val1 = (labels_split_1==0).sum()\n                val2 = (labels_split_1==1).sum()\n                val3 = (labels_split_2==0).sum()\n                val4 = (labels_split_2==1).sum()\n                \n                gini_one = 1 - (val1/(val1+val2))**2 - (val2/(val1+val2))**2\n                gini_two = 1 - (val3/(val3+val4))**2 - (val4/(val3+val4))**2                \n                weighted_gini = (gini_one * (val1 + val2)/(len(train_labels_tree))) + (gini_two * (val3 + val4)/(len(train_labels_tree)))     \n\n                numeric_gini_lst.append(weighted_gini)\n            \n            index_min = np.argmin(numeric_gini_lst)\n            numeric_best_split.append(numeric_vals[index_min])\n            gini_list.append(min(numeric_gini_lst))\n            \n    return gini_list, numeric_best_split, numeric_indices\nginis, numeric_splits, numeric_index = gini_calc(train_data_tree_dummy,train_labels_tree)\nprint(ginis,numeric_splits, numeric_index)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:50.710432Z","iopub.execute_input":"2021-10-13T18:50:50.710714Z","iopub.status.idle":"2021-10-13T18:50:55.334533Z","shell.execute_reply.started":"2021-10-13T18:50:50.710687Z","shell.execute_reply":"2021-10-13T18:50:55.333528Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[0.3333650003885904, 0.461906176612059, 0.4304294062855048, 0.43434842249657063, 0.4688911437727624, 0.4238751054331502, 0.4666626277654732] [6.0, 10.4625] [1, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"numeric_splits, numeric_index","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:55.335814Z","iopub.execute_input":"2021-10-13T18:50:55.336120Z","iopub.status.idle":"2021-10-13T18:50:55.342915Z","shell.execute_reply.started":"2021-10-13T18:50:55.336090Z","shell.execute_reply":"2021-10-13T18:50:55.341650Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"([6.0, 10.4625], [1, 2])"},"metadata":{}}]},{"cell_type":"markdown","source":"# 4.Splitting \n\nOnce we have a function that calculates Gini scores, we can write a function that splits data based on whichever variable has the lowest Gini. The Splitter function checks if the variable is binary or numeric and takes different operations depending on which. It then returns two split dataframes with the indices of the original dataframe in tact","metadata":{}},{"cell_type":"code","source":"def splitter(gini_array, data,labels, numeric_splits, numeric_index):\n    \"\"\"Splits a dataframe based on the best gini value determined from the gini function\"\"\"\n    \n    best_split = np.argmin(gini_array)\n    best_gini = min(gini_array)\n    best_var = data.columns[best_split]\n    is_numeric = False\n    tester = 0\n    numeric_splitter = \"Null\"\n    \n    for i in numeric_index:\n        if best_split == i:\n            tester +=1\n    \n    if tester == 1:\n        is_numeric = True\n        numeric_splitter = numeric_splits[best_split]\n        splitter = numeric_splits[best_split]\n        combined = pd.concat([data, labels], axis=1, sort=False)\n        df1 = combined[combined.iloc[:,best_split] <= splitter]\n        df2 = combined[combined.iloc[:,best_split] > splitter]\n        df1 = df1.drop(df1.columns[best_split], axis=1)\n        df2 = df2.drop(df2.columns[best_split], axis=1)\n        \n        \n        df1_labels = df1.iloc[:,-1]\n        df1 = df1.iloc[:,:-1]\n\n        df2_labels = df2.iloc[:,-1]\n        df2 = df2.iloc[:,:-1]\n        majority_class = 0\n        if sum(df1_labels) > sum(df2_labels):\n            majority_class = 1\n        else:\n            majority_class = 0\n      \n    else:\n        combined = pd.concat([data, labels], axis=1, sort=False)\n\n        df1 = combined[combined.iloc[:,best_split] == 0]\n        df2 = combined[combined.iloc[:,best_split] == 1]\n        df1 = df1.drop(df1.columns[best_split], axis=1)\n        df2 = df2.drop(df2.columns[best_split], axis=1)   \n\n\n        df1_labels = df1.iloc[:,-1]\n        df1 = df1.iloc[:,:-1]\n\n        df2_labels = df2.iloc[:,-1]\n        df2 = df2.iloc[:,:-1]\n        \n        if sum(df1_labels) > sum(df2_labels):\n            majority_class = 1\n        else:\n            majority_class = 0\n    \n\n    return df1, df2, df1_labels, df2_labels, best_gini, best_var, is_numeric, numeric_splitter, majority_class","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:55.344492Z","iopub.execute_input":"2021-10-13T18:50:55.344864Z","iopub.status.idle":"2021-10-13T18:50:55.365888Z","shell.execute_reply.started":"2021-10-13T18:50:55.344831Z","shell.execute_reply":"2021-10-13T18:50:55.364645Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# 5.Recursion \n\nThe next two functions basically do recursion to iteratively go through the data splitting each split to a specified amount. I am specifiying a max depth of 5 but this parameter is changeable (anything from 1-6 should work). I took a list approach to contain all of the information needed to develop the set of rules that are determined later.\n\nNote: The approach I used basically does the following: The main dataframe would be index 0. That splits into two dataframes with indices 1 and 2. Dataframe 1 then splits into two dataframes with indices 3 and 4 while Dataframe two splits into 2 dataframes with indices 5 and 6. This continues for the max depth. So there will be a full tree, then I determined which splits were actually less informative than the previous ones and created rules based on this, collecting the indices of the dataframes that actually reduced Gini.[](http://)","metadata":{}},{"cell_type":"code","source":"def decision_tree(data,labels):\n    \"\"\"Takes a dataframe and labels and applied the Gini and splitter functions to it\"\"\"\n    ginis, numeric_splits, numeric_index = gini_calc(data,labels)\n    df_1, df_2, labs_one, labs_two, best_gini, best_var, is_numeric, numeric_splitter, majority_class = splitter(ginis,data,labels, numeric_splits, numeric_index)\n    \n\n    return best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter, majority_class\n\n\nbest_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter,majority_class = decision_tree(train_data_tree_dummy,train_labels_tree)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:50:55.366946Z","iopub.execute_input":"2021-10-13T18:50:55.367235Z","iopub.status.idle":"2021-10-13T18:51:00.017709Z","shell.execute_reply.started":"2021-10-13T18:50:55.367206Z","shell.execute_reply":"2021-10-13T18:51:00.016636Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def recursive_tree(data,labels,max_depth = 5):\n    \"\"\"Function that takes original data and labels and iteratively splits each dataframe for the full max-depth\"\"\"\n    \n    best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter, majority_class = decision_tree(data,labels)\n    \n    data_frame_splits = []\n    ginis = []\n    labs_list = []\n    best_var_list = []\n    is_numeric_lst = []\n    numer_splitter_lst = []\n    majority_class_list = []\n    data_frame_splits.append(data)\n    ginis.append(.5)\n    labs_list.append(labels)\n    best_var_list.append(\"NA\")\n    is_numeric_lst.append(\"NA\")\n    numer_splitter_lst.append(\"NA\")\n    majority_class_list.append(\"NA\")\n    \n    counter = 0\n    for i in range(max_depth*2):\n        if counter == 0:\n            best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter, majority_class = decision_tree(data,labels)\n        else:\n            best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter,majority_class = decision_tree(data_frame_splits[counter],labs_list[counter])\n        counter +=1\n        data_frame_splits.append(df_1)\n        data_frame_splits.append(df_2)\n        ginis.append(best_gini)\n        ginis.append(best_gini)\n        labs_list.append(labs_one)\n        labs_list.append(labs_two)\n        best_var_list.append(best_var)\n        best_var_list.append(best_var)\n        is_numeric_lst.append(is_numeric)\n        is_numeric_lst.append(is_numeric)\n        numer_splitter_lst.append(numeric_splitter)\n        numer_splitter_lst.append(numeric_splitter)\n        majority_class_list.append(majority_class)\n        if majority_class == 1:\n            majority_class_list.append(majority_class-1)\n        else:\n            majority_class_list.append(majority_class+1)\n        \n    return data_frame_splits, ginis,labs_list,best_var_list, is_numeric_lst,numer_splitter_lst,majority_class_list\n\ndata_frame_splits, ginis,labs_list,best_var_list, is_numeric_lst,numer_splitter_lst,majority_class_list = recursive_tree(train_data_tree_dummy,train_labels_tree)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:00.019269Z","iopub.execute_input":"2021-10-13T18:51:00.019703Z","iopub.status.idle":"2021-10-13T18:51:17.749190Z","shell.execute_reply.started":"2021-10-13T18:51:00.019658Z","shell.execute_reply":"2021-10-13T18:51:17.748164Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in long_scalars\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in long_scalars\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in long_scalars\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in long_scalars\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 6.Pruning \nNow that I have the full tree, I want to find the indices of the dataframes that make up the best tree\n","metadata":{}},{"cell_type":"code","source":"def create_rules(ginis, is_numeric_lst):\n    \"\"\"Returns indices of best tree as well as relavent information indexed by these best indices\"\"\"\n    counter = 0\n    include_list = []\n    for i in range(len(ginis)):\n        if i == 0:\n            include_list.append(counter)\n        \n        elif is_numeric_lst[i] == False and counter % 2 != 0:\n            if ginis[i] <= ginis[int((counter-1)/2)]:\n                include_list.append(counter)\n        elif is_numeric_lst[i] == False and counter % 2 == 0:\n            if ginis[i] <= ginis[int((counter-2)/2)]:\n                 include_list.append(counter)\n        elif is_numeric_lst[i] == True and counter % 2 != 0:\n            if ginis[i] <= ginis[int((counter-1)/2)]:\n                include_list.append(counter)\n        elif is_numeric_lst[i] == True and counter % 2 == 0:\n            if ginis[i] <= ginis[int((counter-2)/2)]:\n                include_list.append(counter)\n        counter +=1\n    \n    best_variables = []\n    for i in include_list:\n        best_variables.append(best_var_list[i])\n    \n    is_numeric_final = []\n    for i in include_list:\n        is_numeric_final.append(is_numeric_lst[i])\n    \n    majority_class_list_final = []\n    for i in include_list:\n        majority_class_list_final.append(majority_class_list[i])\n    \n    numer_splitter_lst_final = []\n    for i in include_list:\n        numer_splitter_lst_final.append(numer_splitter_lst[i])\n    \n    \n    return include_list, is_numeric_final, best_variables, majority_class_list_final, numer_splitter_lst_final\n    \ninclusions, numeric_final, best_vars, majority_class_lst, numer_splitter_lst_final = create_rules(ginis, is_numeric_lst)\nprint(inclusions)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.750814Z","iopub.execute_input":"2021-10-13T18:51:17.751232Z","iopub.status.idle":"2021-10-13T18:51:17.768873Z","shell.execute_reply.started":"2021-10-13T18:51:17.751190Z","shell.execute_reply":"2021-10-13T18:51:17.767712Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 7.Predictions \nThe next function goes through the data with all of the information determined by the rules of the best tree and sets a labels column equal to value determined by the tree.\n\n","metadata":{}},{"cell_type":"code","source":"def yarf(data,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final, counter):\n    \"\"\"yet another recursive function... go through the data and set a column equal to a value determined by the rules\"\"\"\n    if is_numeric_final[counter] == False:\n        x = data[data[best_variables[counter]] == 0].copy()\n        if majority_class_list_final[counter] == 1:\n            x[\"Survived\"] = 0\n        elif majority_class_list_final[counter] == 0:\n            x[\"Survived\"] = 1\n            \n        y = data[data[best_variables[counter]] == 1].copy()\n        if majority_class_list_final[counter] == 0:\n            y[\"Survived\"] = 0\n        elif majority_class_list_final[counter] == 1:\n            y[\"Survived\"] = 1\n        return x, y\n        \n    elif is_numeric_final[counter] == True:\n        x = data[data[best_variables[counter]] <= numer_splitter_lst_final[counter]].copy()\n        if majority_class_list_final[counter] == 1:\n            x[\"Survived\"] = 0\n        elif majority_class_list_final[counter] == 0:\n            x[\"Survived\"] = 1\n        y = data[data[best_variables[counter]] > numer_splitter_lst_final[counter]].copy()\n        if majority_class_list_final[counter] == 0:\n            y[\"Survived\"] = 0\n        elif majority_class_list_final[counter] == 1:\n            y[\"Survived\"] = 1\n        return x, y\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.770164Z","iopub.execute_input":"2021-10-13T18:51:17.770516Z","iopub.status.idle":"2021-10-13T18:51:17.786598Z","shell.execute_reply.started":"2021-10-13T18:51:17.770473Z","shell.execute_reply":"2021-10-13T18:51:17.785293Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def recursive_through_yarf(data,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final, max_depth = 5):\n    \"\"\"Using the yarf function, iteratively save the dataframes with the predictions as a column\"\"\"\n    x, y = yarf(data,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,1)\n    \n    list_of_data_frames = []\n    list_of_data_frames.append(x)\n    list_of_data_frames.append(y)\n    counter = 2\n    frames_counter = 0\n    \n    for i in range(max_depth):\n        x, y = yarf(list_of_data_frames[frames_counter],is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,counter)\n        list_of_data_frames.append(x)\n        list_of_data_frames.append(y)\n        counter+=1\n        frames_counter +=1\n        x, y = yarf(list_of_data_frames[frames_counter],is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,counter)\n        list_of_data_frames.append(x)\n        list_of_data_frames.append(y)\n        counter+=1\n        frames_counter +=1\n    \n    return list_of_data_frames\n\n\n#testing = recursive_through_yarf(train_data_tree_dummy,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,max_depth = 3)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.788082Z","iopub.execute_input":"2021-10-13T18:51:17.788383Z","iopub.status.idle":"2021-10-13T18:51:17.803810Z","shell.execute_reply.started":"2021-10-13T18:51:17.788352Z","shell.execute_reply":"2021-10-13T18:51:17.802576Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Below I am just creating the testing data so it is in the same format as the training data.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data[\"Name\"] = test_data[\"Name\"].str.split(',').str[1]\ntest_data[\"Name\"] = test_data[\"Name\"].str.split('.').str[0]\ntest_data[\"Name\"] = test_data[\"Name\"].str.strip()\ntest_data[\"Age\"] = test_data.groupby(\"Name\").transform(lambda x: x.fillna(x.mean()))['Age']\n#changing sex to be 0 or 1 for female & male\ntest_data['Sex'].replace({'female':0,'male':1},inplace=True)\ntest_data_tree = test_data.iloc[:,[False,True,False, True,True,True,True,False,True,False,False]]\ntest_data_tree.head()\n\ntest_data_tree_dummy = pd.concat([test_data_tree,pd.get_dummies(test_data_tree['Pclass'], prefix='Pclass')],axis=1)\n\ntest_data_tree_dummy.drop([\"Pclass\"],axis=1,inplace=True)\nsib_sp = pd.cut(test_data_tree_dummy[\"SibSp\"], 3,labels=[0,1,2]).tolist()\nparch = pd.cut(test_data_tree_dummy[\"Parch\"], 3,labels=[0,1,2]).tolist()\ntest_data_tree_dummy[\"SibSp2\"] = np.where(test_data_tree_dummy.SibSp==0,0,1)\n\ntest_data_tree_dummy.drop([\"Parch\"],axis=1,inplace=True)\ntest_data_tree_dummy.drop([\"SibSp\"],axis=1,inplace=True)\ntest_data_tree_dummy.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.805088Z","iopub.execute_input":"2021-10-13T18:51:17.805382Z","iopub.status.idle":"2021-10-13T18:51:17.891188Z","shell.execute_reply.started":"2021-10-13T18:51:17.805352Z","shell.execute_reply":"2021-10-13T18:51:17.890052Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   Sex   Age     Fare  Pclass_1  Pclass_2  Pclass_3  SibSp2\n0    1  34.5   7.8292         0         0         1       0\n1    0  47.0   7.0000         0         0         1       1\n2    1  62.0   9.6875         0         1         0       0\n3    1  27.0   8.6625         0         0         1       0\n4    0  22.0  12.2875         0         0         1       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>SibSp2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>34.5</td>\n      <td>7.8292</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>47.0</td>\n      <td>7.0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>62.0</td>\n      <td>9.6875</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>27.0</td>\n      <td>8.6625</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>12.2875</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"testing = recursive_through_yarf(test_data_tree_dummy,numeric_final,best_vars, inclusions,majority_class_lst,numer_splitter_lst_final,max_depth = 5)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.892552Z","iopub.execute_input":"2021-10-13T18:51:17.892870Z","iopub.status.idle":"2021-10-13T18:51:17.922552Z","shell.execute_reply.started":"2021-10-13T18:51:17.892839Z","shell.execute_reply":"2021-10-13T18:51:17.921189Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def make_predictions(testing_data, inclusions):\n    \"\"\"When merging dataframes, only want to merge leaf nodes. This function takes all the leaf nodes and merges together\"\"\"\n    \n    for i in inclusions:\n        if i %2 !=0:\n            try:\n                inclusions.remove(int((i-1)/2))\n            except:\n                pass\n        elif i %2 ==0:\n            try:\n                inclusions.remove(int((i-2)/2))\n            except:\n                pass\n    inclusions2 = []\n    for i in inclusions:\n        inclusions2.append(i-1)\n        \n    dataframes_to_keep = []\n    for i in inclusions2:\n        dataframes_to_keep.append(testing_data[i])\n\n\n    preds = pd.concat(dataframes_to_keep, axis=0).sort_index(axis = 0)\n\n    return preds\n    \npreds = make_predictions(testing, inclusions)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.923972Z","iopub.execute_input":"2021-10-13T18:51:17.924294Z","iopub.status.idle":"2021-10-13T18:51:17.940961Z","shell.execute_reply.started":"2021-10-13T18:51:17.924260Z","shell.execute_reply":"2021-10-13T18:51:17.939982Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.942494Z","iopub.execute_input":"2021-10-13T18:51:17.943034Z","iopub.status.idle":"2021-10-13T18:51:17.954865Z","shell.execute_reply.started":"2021-10-13T18:51:17.943002Z","shell.execute_reply":"2021-10-13T18:51:17.953773Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(418, 8)"},"metadata":{}}]},{"cell_type":"code","source":"test_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.956521Z","iopub.execute_input":"2021-10-13T18:51:17.956857Z","iopub.status.idle":"2021-10-13T18:51:17.967601Z","shell.execute_reply.started":"2021-10-13T18:51:17.956826Z","shell.execute_reply":"2021-10-13T18:51:17.966316Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(418, 11)"},"metadata":{}}]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.969237Z","iopub.execute_input":"2021-10-13T18:51:17.969604Z","iopub.status.idle":"2021-10-13T18:51:17.992718Z","shell.execute_reply.started":"2021-10-13T18:51:17.969571Z","shell.execute_reply":"2021-10-13T18:51:17.991891Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Pclass Name  Sex   Age  SibSp  Parch   Ticket     Fare Cabin  \\\n0          892       3   Mr    1  34.5      0      0   330911   7.8292   NaN   \n1          893       3  Mrs    0  47.0      1      0   363272   7.0000   NaN   \n2          894       2   Mr    1  62.0      0      0   240276   9.6875   NaN   \n3          895       3   Mr    1  27.0      0      0   315154   8.6625   NaN   \n4          896       3  Mrs    0  22.0      1      1  3101298  12.2875   NaN   \n\n  Embarked  \n0        Q  \n1        S  \n2        Q  \n3        S  \n4        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Mrs</td>\n      <td>0</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Mrs</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 8.Submission ","metadata":{}},{"cell_type":"code","source":"data = {'PassengerId': test_data[\"PassengerId\"].values, 'Survived':preds[\"Survived\"].values}\n\ndf_submission = pd.DataFrame(data)\n\ndf_submission.to_csv(\"submission_decision_tree.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T18:51:17.994000Z","iopub.execute_input":"2021-10-13T18:51:17.994290Z","iopub.status.idle":"2021-10-13T18:51:18.003524Z","shell.execute_reply.started":"2021-10-13T18:51:17.994261Z","shell.execute_reply":"2021-10-13T18:51:18.002799Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"Final score on testing Set: 0.76076","metadata":{}}]}
