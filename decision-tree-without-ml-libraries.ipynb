{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020371,
     "end_time": "2020-09-26T07:08:44.779657",
     "exception": false,
     "start_time": "2020-09-26T07:08:44.759286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decision Tree: Classifying the Titanic Dataset Without Machine Learning Libraries\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "### 2. Preprocessing\n",
    "\n",
    "### 3. Impurity Measure\n",
    "\n",
    "### 4. Splitting Data\n",
    "\n",
    "### 5. Getting Full Tree\n",
    "\n",
    "### 6. Recursive Partitioning\n",
    "\n",
    "### 7. Making Predictions With Pruned Tree\n",
    "\n",
    "### 8. Submission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018192,
     "end_time": "2020-09-26T07:08:44.817661",
     "exception": false,
     "start_time": "2020-09-26T07:08:44.799469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.Introduction \n",
    "\n",
    "![](http://)This is my attempt at creating a decision tree without using only numpy and pandas libraries. I did not reference other people's code or approaches; rather I watched the StatQuest video on Decision Trees (https://www.youtube.com/watch?v=7VeUPuFGJHk) to understand the algorithm and took my own approach to code it. This was simply meant as a challenge and a learning exercise for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:44.862402Z",
     "iopub.status.busy": "2020-09-26T07:08:44.861622Z",
     "iopub.status.idle": "2020-09-26T07:08:44.882207Z",
     "shell.execute_reply": "2020-09-26T07:08:44.882768Z"
    },
    "papermill": {
     "duration": 0.04685,
     "end_time": "2020-09-26T07:08:44.882961",
     "exception": false,
     "start_time": "2020-09-26T07:08:44.836111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import itertools\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "#train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018778,
     "end_time": "2020-09-26T07:08:44.922989",
     "exception": false,
     "start_time": "2020-09-26T07:08:44.904211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2.Preprocessing \n",
    "The age variable has missing data but all of the other numeric columns are fine. An approach is to group data by another variable and find the average age for each group and impute the average into the missing values. I will take group by the title of each person since people with similar title may have similar ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:44.966460Z",
     "iopub.status.busy": "2020-09-26T07:08:44.965440Z",
     "iopub.status.idle": "2020-09-26T07:08:45.023884Z",
     "shell.execute_reply": "2020-09-26T07:08:45.024359Z"
    },
    "papermill": {
     "duration": 0.081385,
     "end_time": "2020-09-26T07:08:45.024523",
     "exception": false,
     "start_time": "2020-09-26T07:08:44.943138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Master',\n",
       "       'Miss', 'Mlle', 'Mme', 'Mr', 'Mrs', 'Ms', 'Rev', 'Sir', 'the Countess'],\n",
       "      dtype='object', name='Name')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Name\"] = train_data[\"Name\"].str.split(',').str[1]\n",
    "train_data[\"Name\"] = train_data[\"Name\"].str.split('.').str[0]\n",
    "train_data[\"Name\"] = train_data[\"Name\"].str.strip()\n",
    "x = train_data.groupby('Name').agg(['count']).index.get_level_values('Name')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:45.076176Z",
     "iopub.status.busy": "2020-09-26T07:08:45.073306Z",
     "iopub.status.idle": "2020-09-26T07:08:45.155477Z",
     "shell.execute_reply": "2020-09-26T07:08:45.155972Z"
    },
    "papermill": {
     "duration": 0.110216,
     "end_time": "2020-09-26T07:08:45.156128",
     "exception": false,
     "start_time": "2020-09-26T07:08:45.045912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    Mr    1  22.0      1      0   \n",
       "1            2         1       1   Mrs    0  38.0      1      0   \n",
       "2            3         1       3  Miss    0  26.0      0      0   \n",
       "3            4         1       1   Mrs    0  35.0      1      0   \n",
       "4            5         0       3    Mr    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Age\"] = train_data.groupby(\"Name\").transform(lambda x: x.fillna(x.mean()))['Age']\n",
    "#changing sex to be 0 or 1 for female & male\n",
    "train_data['Sex'].replace({'female':0,'male':1},inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:45.207732Z",
     "iopub.status.busy": "2020-09-26T07:08:45.199418Z",
     "iopub.status.idle": "2020-09-26T07:08:45.234979Z",
     "shell.execute_reply": "2020-09-26T07:08:45.234268Z"
    },
    "papermill": {
     "duration": 0.058802,
     "end_time": "2020-09-26T07:08:45.235103",
     "exception": false,
     "start_time": "2020-09-26T07:08:45.176301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>29.754659</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.277179</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.773973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.898148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Sex         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean     2.308642    0.647587   29.754659    0.523008    0.381594   32.204208\n",
       "std      0.836071    0.477990   13.277179    1.102743    0.806057   49.693429\n",
       "min      1.000000    0.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      2.000000    0.000000   21.773973    0.000000    0.000000    7.910400\n",
       "50%      3.000000    1.000000   30.000000    0.000000    0.000000   14.454200\n",
       "75%      3.000000    1.000000   35.898148    1.000000    0.000000   31.000000\n",
       "max      3.000000    1.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tree = train_data.iloc[:,[False,False,True, False,True,True,True,True,False,True,False,False]]\n",
    "train_labels_tree = train_data.iloc[:,1]\n",
    "train_data_tree.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021176,
     "end_time": "2020-09-26T07:08:45.277098",
     "exception": false,
     "start_time": "2020-09-26T07:08:45.255922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the categorical variables, I'm transforming the columns into columns of dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:45.331546Z",
     "iopub.status.busy": "2020-09-26T07:08:45.330550Z",
     "iopub.status.idle": "2020-09-26T07:08:45.394865Z",
     "shell.execute_reply": "2020-09-26T07:08:45.395340Z"
    },
    "papermill": {
     "duration": 0.097593,
     "end_time": "2020-09-26T07:08:45.395491",
     "exception": false,
     "start_time": "2020-09-26T07:08:45.297898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>SibSp2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.647587</td>\n",
       "      <td>29.754659</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.317621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.277179</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.465813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.773973</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.898148</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sex         Age        Fare    Pclass_1    Pclass_2    Pclass_3  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.647587   29.754659   32.204208    0.242424    0.206510    0.551066   \n",
       "std      0.477990   13.277179   49.693429    0.428790    0.405028    0.497665   \n",
       "min      0.000000    0.420000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   21.773973    7.910400    0.000000    0.000000    0.000000   \n",
       "50%      1.000000   30.000000   14.454200    0.000000    0.000000    1.000000   \n",
       "75%      1.000000   35.898148   31.000000    0.000000    0.000000    1.000000   \n",
       "max      1.000000   80.000000  512.329200    1.000000    1.000000    1.000000   \n",
       "\n",
       "           SibSp2  \n",
       "count  891.000000  \n",
       "mean     0.317621  \n",
       "std      0.465813  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to create dummy variable columns for the Pclass variable. The other variables are either binary or numeric\n",
    "train_data_tree_dummy = pd.concat([train_data_tree,pd.get_dummies(train_data_tree['Pclass'], prefix='Pclass')],axis=1)\n",
    "\n",
    "train_data_tree_dummy.drop([\"Pclass\"],axis=1,inplace=True)\n",
    "sib_sp = pd.cut(train_data_tree_dummy[\"SibSp\"], 3,labels=[0,1,2]).tolist()\n",
    "parch = pd.cut(train_data_tree_dummy[\"Parch\"], 3,labels=[0,1,2]).tolist()\n",
    "\n",
    "train_data_tree_dummy.drop([\"Parch\"],axis=1,inplace=True)\n",
    "train_data_tree_dummy[\"SibSp2\"] = np.where(train_data_tree_dummy.SibSp==0,0,1)\n",
    "train_data_tree_dummy.drop([\"SibSp\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "train_data_tree_dummy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021265,
     "end_time": "2020-09-26T07:08:45.439051",
     "exception": false,
     "start_time": "2020-09-26T07:08:45.417786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3.Impurity \n",
    "For the measure of impurity, I'm using Gini. Lower values indicate better splits, so this function calculates Gini for each column to determine the best variable to split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:45.486834Z",
     "iopub.status.busy": "2020-09-26T07:08:45.485781Z",
     "iopub.status.idle": "2020-09-26T07:08:50.861734Z",
     "shell.execute_reply": "2020-09-26T07:08:50.862211Z"
    },
    "papermill": {
     "duration": 5.401305,
     "end_time": "2020-09-26T07:08:50.862361",
     "exception": false,
     "start_time": "2020-09-26T07:08:45.461056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333650003885904,\n",
       " 0.46190617661205907,\n",
       " 0.4304294062855048,\n",
       " 0.43434842249657063,\n",
       " 0.4688911437727624,\n",
       " 0.4238751054331502,\n",
       " 0.46666262776547324]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_calc(data,labels):\n",
    "    best_gini = []\n",
    "    numeric_best_split = []\n",
    "    numeric_indices = []\n",
    "    counter = -1\n",
    "    zeros = np.zeros(len(labels))\n",
    "    ones = zeros + 1 \n",
    "    zero_zero = 0\n",
    "    zero_one = 0\n",
    "    one_zero = 0\n",
    "    one_one = 0\n",
    "    gini_one = 0\n",
    "    gini_two = 0\n",
    "    weighted_gini = 0\n",
    "    \n",
    "    for i in data:\n",
    "        counter +=1\n",
    "        if data[i].dtype == 'int64' or data[i].dtype == 'uint8':\n",
    "            list2 = []\n",
    "            zero_zero = sum(np.logical_and(data[i] == labels, zeros == data[i])) #get counts of different combinations\n",
    "            zero_one = sum(np.logical_and(data[i] != labels, zeros == data[i]))\n",
    "            one_zero = sum(np.logical_and(data[i] != labels, ones == data[i]))\n",
    "            one_one = sum(np.logical_and(data[i] == labels, ones == data[i]))\n",
    "\n",
    "            if (one_one+one_zero) == 0:\n",
    "                part_one = 0\n",
    "                part_two = 0\n",
    "            else:\n",
    "                part_one = one_one/(one_one+one_zero)\n",
    "                part_two = one_zero/(one_one+one_zero)\n",
    "                \n",
    "            if (zero_zero+zero_one) == 0:\n",
    "                part_three = 0\n",
    "                part_four = 0\n",
    "            else:\n",
    "                part_three = zero_zero/(zero_zero+zero_one)\n",
    "                part_four = zero_one/(zero_one+zero_zero)\n",
    "\n",
    "                \n",
    "            gini_one = 1 - (part_one**2) - (part_two**2)\n",
    "            gini_two = 1 - (part_three**2) - (part_four**2)\n",
    "            weighted_gini = (gini_one * (one_one + one_zero)/(len(labels))) + (gini_two * (zero_zero + zero_one)/(len(labels)))\n",
    "        \n",
    "            best_gini.append(weighted_gini)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            numeric_indices.append(counter)\n",
    "            numeric_vals = np.array(data.sort_values([i])[i].reset_index(drop=True))\n",
    "            index_min = 0\n",
    "            avg_lst = []\n",
    "            numeric_gini_lst = []\n",
    "            for h in range(len(numeric_vals)-1):\n",
    "                avg_lst.append((numeric_vals[h]+numeric_vals[h+1])/2)\n",
    "            zeros = np.zeros(len(labels))\n",
    "            ones = zeros + 1 \n",
    "            \n",
    "            for val in avg_lst:\n",
    "                vals_array = ones*val\n",
    "\n",
    "                zero_zero = sum(np.logical_and(data[i] <= vals_array, zeros == labels)) #get counts of different combinations\n",
    "                zero_one = sum(np.logical_and(data[i] <= vals_array, ones == labels))\n",
    "                one_zero = sum(np.logical_and(data[i] >= vals_array, zeros == labels))\n",
    "                one_one = sum(np.logical_and(data[i] >= vals_array, ones == labels))\n",
    "\n",
    "                if (one_one+one_zero) == 0:\n",
    "                    part_one = 0\n",
    "                    part_two = 0\n",
    "                else:\n",
    "                    part_one = one_one/(one_one+one_zero)\n",
    "                    part_two = one_zero/(one_one+one_zero)\n",
    "\n",
    "                if (zero_zero+zero_one) == 0:\n",
    "                    part_three = 0\n",
    "                    part_four = 0\n",
    "                else:\n",
    "                    part_three = zero_zero/(zero_zero+zero_one)\n",
    "                    part_four = zero_one/(zero_one+zero_zero)\n",
    "                \n",
    "                gini_one = 1 - (part_one**2) - (part_two**2)\n",
    "                gini_two = 1 - (part_three**2) - (part_four**2)\n",
    "                    \n",
    "                weighted_gini = (gini_one * (one_one + one_zero)/(len(labels))) + (gini_two * (zero_zero + zero_one)/(len(labels))) \n",
    "                \n",
    "                \n",
    "                \n",
    "                numeric_gini_lst.append(weighted_gini)\n",
    "            index_min = np.argmin(numeric_gini_lst)\n",
    "            numeric_best_split.append(numeric_vals[index_min])\n",
    "            best_gini.append(min(numeric_gini_lst))\n",
    "        \n",
    "    return best_gini, numeric_best_split, numeric_indices\n",
    "            \n",
    "ginis, numeric_splits, numeric_index = gini_calc(train_data_tree_dummy,train_labels_tree)\n",
    "ginis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023368,
     "end_time": "2020-09-26T07:08:50.909012",
     "exception": false,
     "start_time": "2020-09-26T07:08:50.885644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.Splitting \n",
    "\n",
    "Once we have a function that calculates Gini scores, we can write a function that splits data based on whichever variable has the lowest Gini. The Splitter function checks if the variable is binary or numeric and takes different operations depending on which. It then returns two split dataframes with the indices of the original dataframe in tact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:50.959018Z",
     "iopub.status.busy": "2020-09-26T07:08:50.958275Z",
     "iopub.status.idle": "2020-09-26T07:08:50.979495Z",
     "shell.execute_reply": "2020-09-26T07:08:50.978842Z"
    },
    "papermill": {
     "duration": 0.048098,
     "end_time": "2020-09-26T07:08:50.979706",
     "exception": false,
     "start_time": "2020-09-26T07:08:50.931608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def splitter(gini_array, data,labels, numeric_splits, numeric_index):\n",
    "    \"\"\"Splits a dataframe based on the best gini value determined from the gini function\"\"\"\n",
    "    \n",
    "    best_split = np.argmin(gini_array)\n",
    "    best_gini = min(gini_array)\n",
    "    best_var = data.columns[best_split]\n",
    "    is_numeric = False\n",
    "    tester = 0\n",
    "    numeric_splitter = \"Null\"\n",
    "    \n",
    "    for i in numeric_index:\n",
    "        if best_split == i:\n",
    "            tester +=1\n",
    "    \n",
    "    if tester == 1:\n",
    "        is_numeric = True\n",
    "        numeric_splitter = numeric_splits[best_split]\n",
    "        splitter = numeric_splits[best_split]\n",
    "        combined = pd.concat([data, labels], axis=1, sort=False)\n",
    "        df1 = combined[combined.iloc[:,best_split] <= splitter]\n",
    "        df2 = combined[combined.iloc[:,best_split] > splitter]\n",
    "        df1 = df1.drop(df1.columns[best_split], axis=1)\n",
    "        df2 = df2.drop(df2.columns[best_split], axis=1)\n",
    "        \n",
    "        \n",
    "        df1_labels = df1.iloc[:,-1]\n",
    "        df1 = df1.iloc[:,:-1]\n",
    "\n",
    "        df2_labels = df2.iloc[:,-1]\n",
    "        df2 = df2.iloc[:,:-1]\n",
    "        majority_class = 0\n",
    "        if sum(df1_labels) > sum(df2_labels):\n",
    "            majority_class = 1\n",
    "        else:\n",
    "            majority_class = 0\n",
    "      \n",
    "    else:\n",
    "        combined = pd.concat([data, labels], axis=1, sort=False)\n",
    "\n",
    "        df1 = combined[combined.iloc[:,best_split] == 0]\n",
    "        df2 = combined[combined.iloc[:,best_split] == 1]\n",
    "        df1 = df1.drop(df1.columns[best_split], axis=1)\n",
    "        df2 = df2.drop(df2.columns[best_split], axis=1)   \n",
    "\n",
    "\n",
    "        df1_labels = df1.iloc[:,-1]\n",
    "        df1 = df1.iloc[:,:-1]\n",
    "\n",
    "        df2_labels = df2.iloc[:,-1]\n",
    "        df2 = df2.iloc[:,:-1]\n",
    "        \n",
    "        if sum(df1_labels) > sum(df2_labels):\n",
    "            majority_class = 1\n",
    "        else:\n",
    "            majority_class = 0\n",
    "    \n",
    "\n",
    "    return df1, df2, df1_labels, df2_labels, best_gini, best_var, is_numeric, numeric_splitter, majority_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025458,
     "end_time": "2020-09-26T07:08:51.028418",
     "exception": false,
     "start_time": "2020-09-26T07:08:51.002960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5.Recursion \n",
    "\n",
    "The next two functions basically do recursion to iteratively go through the data splitting each split to a specified amount. I am specifiying a max depth of 5 but this parameter is changeable (anything from 1-6 should work). I took a list approach to contain all of the information needed to develop the set of rules that are determined later.\n",
    "\n",
    "Note: The approach I used basically does the following: The main dataframe would be index 0. That splits into two dataframes with indices 1 and 2. Dataframe 1 then splits into two dataframes with indices 3 and 4 while Dataframe two splits into 2 dataframes with indices 5 and 6. This continues for the max depth. So there will be a full tree, then I determined which splits were actually less informative than the previous ones and created rules based on this, collecting the indices of the dataframes that actually reduced Gini.[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:51.083406Z",
     "iopub.status.busy": "2020-09-26T07:08:51.082139Z",
     "iopub.status.idle": "2020-09-26T07:08:56.245467Z",
     "shell.execute_reply": "2020-09-26T07:08:56.244890Z"
    },
    "papermill": {
     "duration": 5.191393,
     "end_time": "2020-09-26T07:08:56.245595",
     "exception": false,
     "start_time": "2020-09-26T07:08:51.054202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decision_tree(data,labels):\n",
    "    \"\"\"Takes a dataframe and labels and applied the Gini and splitter functions to it\"\"\"\n",
    "    ginis, numeric_splits, numeric_index = gini_calc(data,labels)\n",
    "    df_1, df_2, labs_one, labs_two, best_gini, best_var, is_numeric, numeric_splitter, majority_class = splitter(ginis,data,labels, numeric_splits, numeric_index)\n",
    "    \n",
    "\n",
    "    return best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter, majority_class\n",
    "\n",
    "\n",
    "best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter,majority_class = decision_tree(train_data_tree_dummy,train_labels_tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:08:56.489992Z",
     "iopub.status.busy": "2020-09-26T07:08:56.313530Z",
     "iopub.status.idle": "2020-09-26T07:09:15.258989Z",
     "shell.execute_reply": "2020-09-26T07:09:15.257864Z"
    },
    "papermill": {
     "duration": 18.99085,
     "end_time": "2020-09-26T07:09:15.259127",
     "exception": false,
     "start_time": "2020-09-26T07:08:56.268277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_tree(data,labels,max_depth = 5):\n",
    "    \"\"\"Function that takes original data and labels and iteratively splits each dataframe for the full max-depth\"\"\"\n",
    "    \n",
    "    best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter, majority_class = decision_tree(data,labels)\n",
    "    \n",
    "    data_frame_splits = []\n",
    "    ginis = []\n",
    "    labs_list = []\n",
    "    best_var_list = []\n",
    "    is_numeric_lst = []\n",
    "    numer_splitter_lst = []\n",
    "    majority_class_list = []\n",
    "    data_frame_splits.append(data)\n",
    "    ginis.append(.5)\n",
    "    labs_list.append(labels)\n",
    "    best_var_list.append(\"NA\")\n",
    "    is_numeric_lst.append(\"NA\")\n",
    "    numer_splitter_lst.append(\"NA\")\n",
    "    majority_class_list.append(\"NA\")\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(max_depth*2):\n",
    "        if counter == 0:\n",
    "            best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter, majority_class = decision_tree(data,labels)\n",
    "        else:\n",
    "            best_gini, df_1, df_2, labs_one, labs_two, best_var, is_numeric, numeric_splitter,majority_class = decision_tree(data_frame_splits[counter],labs_list[counter])\n",
    "        counter +=1\n",
    "        data_frame_splits.append(df_1)\n",
    "        data_frame_splits.append(df_2)\n",
    "        ginis.append(best_gini)\n",
    "        ginis.append(best_gini)\n",
    "        labs_list.append(labs_one)\n",
    "        labs_list.append(labs_two)\n",
    "        best_var_list.append(best_var)\n",
    "        best_var_list.append(best_var)\n",
    "        is_numeric_lst.append(is_numeric)\n",
    "        is_numeric_lst.append(is_numeric)\n",
    "        numer_splitter_lst.append(numeric_splitter)\n",
    "        numer_splitter_lst.append(numeric_splitter)\n",
    "        majority_class_list.append(majority_class)\n",
    "        if majority_class == 1:\n",
    "            majority_class_list.append(majority_class-1)\n",
    "        else:\n",
    "            majority_class_list.append(majority_class+1)\n",
    "        \n",
    "    return data_frame_splits, ginis,labs_list,best_var_list, is_numeric_lst,numer_splitter_lst,majority_class_list\n",
    "\n",
    "data_frame_splits, ginis,labs_list,best_var_list, is_numeric_lst,numer_splitter_lst,majority_class_list = recursive_tree(train_data_tree_dummy,train_labels_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022929,
     "end_time": "2020-09-26T07:09:15.304774",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.281845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.Pruning \n",
    "Now that I have the full tree, I want to find the indices of the dataframes that make up the best tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:15.372950Z",
     "iopub.status.busy": "2020-09-26T07:09:15.371532Z",
     "iopub.status.idle": "2020-09-26T07:09:15.378087Z",
     "shell.execute_reply": "2020-09-26T07:09:15.377119Z"
    },
    "papermill": {
     "duration": 0.050095,
     "end_time": "2020-09-26T07:09:15.378257",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.328162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "def create_rules(ginis, is_numeric_lst):\n",
    "    \"\"\"Returns indices of best tree as well as relavent information indexed by these best indices\"\"\"\n",
    "    counter = 0\n",
    "    include_list = []\n",
    "    for i in range(len(ginis)):\n",
    "        if i == 0:\n",
    "            include_list.append(counter)\n",
    "        \n",
    "        elif is_numeric_lst[i] == False and counter % 2 != 0:\n",
    "            if ginis[i] <= ginis[int((counter-1)/2)]:\n",
    "                include_list.append(counter)\n",
    "        elif is_numeric_lst[i] == False and counter % 2 == 0:\n",
    "            if ginis[i] <= ginis[int((counter-2)/2)]:\n",
    "                 include_list.append(counter)\n",
    "        elif is_numeric_lst[i] == True and counter % 2 != 0:\n",
    "            if ginis[i] <= ginis[int((counter-1)/2)]:\n",
    "                include_list.append(counter)\n",
    "        elif is_numeric_lst[i] == True and counter % 2 == 0:\n",
    "            if ginis[i] <= ginis[int((counter-2)/2)]:\n",
    "                include_list.append(counter)\n",
    "        counter +=1\n",
    "    \n",
    "    best_variables = []\n",
    "    for i in include_list:\n",
    "        best_variables.append(best_var_list[i])\n",
    "    \n",
    "    is_numeric_final = []\n",
    "    for i in include_list:\n",
    "        is_numeric_final.append(is_numeric_lst[i])\n",
    "    \n",
    "    majority_class_list_final = []\n",
    "    for i in include_list:\n",
    "        majority_class_list_final.append(majority_class_list[i])\n",
    "    \n",
    "    numer_splitter_lst_final = []\n",
    "    for i in include_list:\n",
    "        numer_splitter_lst_final.append(numer_splitter_lst[i])\n",
    "    \n",
    "    \n",
    "    return include_list, is_numeric_final, best_variables, majority_class_list_final, numer_splitter_lst_final\n",
    "    \n",
    "inclusions, numeric_final, best_vars, majority_class_lst, numer_splitter_lst_final = create_rules(ginis, is_numeric_lst)\n",
    "print(inclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027903,
     "end_time": "2020-09-26T07:09:15.443961",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.416058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7.Predictions \n",
    "The next function goes through the data with all of the information determined by the rules of the best tree and sets a labels column equal to value determined by the tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:15.503707Z",
     "iopub.status.busy": "2020-09-26T07:09:15.503027Z",
     "iopub.status.idle": "2020-09-26T07:09:15.521621Z",
     "shell.execute_reply": "2020-09-26T07:09:15.522564Z"
    },
    "papermill": {
     "duration": 0.047486,
     "end_time": "2020-09-26T07:09:15.522827",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.475341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yarf(data,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final, counter):\n",
    "    \"\"\"yet another recursive function... go through the data and set a column equal to a value determined by the rules\"\"\"\n",
    "    if is_numeric_final[counter] == False:\n",
    "        x = data[data[best_variables[counter]] == 0].copy()\n",
    "        if majority_class_list_final[counter] == 1:\n",
    "            x[\"Survived\"] = 0\n",
    "        elif majority_class_list_final[counter] == 0:\n",
    "            x[\"Survived\"] = 1\n",
    "            \n",
    "        y = data[data[best_variables[counter]] == 1].copy()\n",
    "        if majority_class_list_final[counter] == 0:\n",
    "            y[\"Survived\"] = 0\n",
    "        elif majority_class_list_final[counter] == 1:\n",
    "            y[\"Survived\"] = 1\n",
    "        return x, y\n",
    "        \n",
    "    elif is_numeric_final[counter] == True:\n",
    "        x = data[data[best_variables[counter]] <= numer_splitter_lst_final[counter]].copy()\n",
    "        if majority_class_list_final[counter] == 1:\n",
    "            x[\"Survived\"] = 0\n",
    "        elif majority_class_list_final[counter] == 0:\n",
    "            x[\"Survived\"] = 1\n",
    "        y = data[data[best_variables[counter]] > numer_splitter_lst_final[counter]].copy()\n",
    "        if majority_class_list_final[counter] == 0:\n",
    "            y[\"Survived\"] = 0\n",
    "        elif majority_class_list_final[counter] == 1:\n",
    "            y[\"Survived\"] = 1\n",
    "        return x, y\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:15.600241Z",
     "iopub.status.busy": "2020-09-26T07:09:15.599059Z",
     "iopub.status.idle": "2020-09-26T07:09:15.601325Z",
     "shell.execute_reply": "2020-09-26T07:09:15.602151Z"
    },
    "papermill": {
     "duration": 0.047011,
     "end_time": "2020-09-26T07:09:15.602363",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.555352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_through_yarf(data,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final, max_depth = 5):\n",
    "    \"\"\"Using the yarf function, iteratively save the dataframes with the predictions as a column\"\"\"\n",
    "    x, y = yarf(data,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,1)\n",
    "    \n",
    "    list_of_data_frames = []\n",
    "    list_of_data_frames.append(x)\n",
    "    list_of_data_frames.append(y)\n",
    "    counter = 2\n",
    "    frames_counter = 0\n",
    "    \n",
    "    for i in range(max_depth):\n",
    "        x, y = yarf(list_of_data_frames[frames_counter],is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,counter)\n",
    "        list_of_data_frames.append(x)\n",
    "        list_of_data_frames.append(y)\n",
    "        counter+=1\n",
    "        frames_counter +=1\n",
    "        x, y = yarf(list_of_data_frames[frames_counter],is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,counter)\n",
    "        list_of_data_frames.append(x)\n",
    "        list_of_data_frames.append(y)\n",
    "        counter+=1\n",
    "        frames_counter +=1\n",
    "    \n",
    "    return list_of_data_frames\n",
    "\n",
    "\n",
    "#testing = recursive_through_yarf(train_data_tree_dummy,is_numeric_final,best_variables, inclusions,majority_class_list_final,numer_splitter_lst_final,max_depth = 3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023873,
     "end_time": "2020-09-26T07:09:15.662618",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.638745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below I am just creating the testing data so it is in the same format as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:15.714551Z",
     "iopub.status.busy": "2020-09-26T07:09:15.713665Z",
     "iopub.status.idle": "2020-09-26T07:09:15.798576Z",
     "shell.execute_reply": "2020-09-26T07:09:15.797865Z"
    },
    "papermill": {
     "duration": 0.112106,
     "end_time": "2020-09-26T07:09:15.798694",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.686588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>SibSp2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex   Age     Fare  Pclass_1  Pclass_2  Pclass_3  SibSp2\n",
       "0    1  34.5   7.8292         0         0         1       0\n",
       "1    0  47.0   7.0000         0         0         1       1\n",
       "2    1  62.0   9.6875         0         1         0       0\n",
       "3    1  27.0   8.6625         0         0         1       0\n",
       "4    0  22.0  12.2875         0         0         1       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data[\"Name\"] = test_data[\"Name\"].str.split(',').str[1]\n",
    "test_data[\"Name\"] = test_data[\"Name\"].str.split('.').str[0]\n",
    "test_data[\"Name\"] = test_data[\"Name\"].str.strip()\n",
    "test_data[\"Age\"] = test_data.groupby(\"Name\").transform(lambda x: x.fillna(x.mean()))['Age']\n",
    "#changing sex to be 0 or 1 for female & male\n",
    "test_data['Sex'].replace({'female':0,'male':1},inplace=True)\n",
    "test_data_tree = test_data.iloc[:,[False,True,False, True,True,True,True,False,True,False,False]]\n",
    "test_data_tree.head()\n",
    "\n",
    "test_data_tree_dummy = pd.concat([test_data_tree,pd.get_dummies(test_data_tree['Pclass'], prefix='Pclass')],axis=1)\n",
    "\n",
    "test_data_tree_dummy.drop([\"Pclass\"],axis=1,inplace=True)\n",
    "sib_sp = pd.cut(test_data_tree_dummy[\"SibSp\"], 3,labels=[0,1,2]).tolist()\n",
    "parch = pd.cut(test_data_tree_dummy[\"Parch\"], 3,labels=[0,1,2]).tolist()\n",
    "test_data_tree_dummy[\"SibSp2\"] = np.where(test_data_tree_dummy.SibSp==0,0,1)\n",
    "\n",
    "test_data_tree_dummy.drop([\"Parch\"],axis=1,inplace=True)\n",
    "test_data_tree_dummy.drop([\"SibSp\"],axis=1,inplace=True)\n",
    "test_data_tree_dummy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:15.874048Z",
     "iopub.status.busy": "2020-09-26T07:09:15.865837Z",
     "iopub.status.idle": "2020-09-26T07:09:15.885827Z",
     "shell.execute_reply": "2020-09-26T07:09:15.885055Z"
    },
    "papermill": {
     "duration": 0.062417,
     "end_time": "2020-09-26T07:09:15.885969",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.823552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing = recursive_through_yarf(test_data_tree_dummy,numeric_final,best_vars, inclusions,majority_class_lst,numer_splitter_lst_final,max_depth = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:15.955489Z",
     "iopub.status.busy": "2020-09-26T07:09:15.954244Z",
     "iopub.status.idle": "2020-09-26T07:09:15.958177Z",
     "shell.execute_reply": "2020-09-26T07:09:15.957596Z"
    },
    "papermill": {
     "duration": 0.046297,
     "end_time": "2020-09-26T07:09:15.958305",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.912008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(testing_data, inclusions):\n",
    "    \"\"\"When merging dataframes, only want to merge leaf nodes. This function takes all the leaf nodes and merges together\"\"\"\n",
    "    \n",
    "    for i in inclusions:\n",
    "        if i %2 !=0:\n",
    "            try:\n",
    "                inclusions.remove(int((i-1)/2))\n",
    "            except:\n",
    "                pass\n",
    "        elif i %2 ==0:\n",
    "            try:\n",
    "                inclusions.remove(int((i-2)/2))\n",
    "            except:\n",
    "                pass\n",
    "    inclusions2 = []\n",
    "    for i in inclusions:\n",
    "        inclusions2.append(i-1)\n",
    "        \n",
    "    dataframes_to_keep = []\n",
    "    for i in inclusions2:\n",
    "        dataframes_to_keep.append(testing_data[i])\n",
    "\n",
    "\n",
    "    preds = pd.concat(dataframes_to_keep, axis=0).sort_index(axis = 0)\n",
    "\n",
    "    return preds\n",
    "    \n",
    "preds = make_predictions(testing, inclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:16.015184Z",
     "iopub.status.busy": "2020-09-26T07:09:16.014345Z",
     "iopub.status.idle": "2020-09-26T07:09:16.017162Z",
     "shell.execute_reply": "2020-09-26T07:09:16.017852Z"
    },
    "papermill": {
     "duration": 0.034408,
     "end_time": "2020-09-26T07:09:16.018019",
     "exception": false,
     "start_time": "2020-09-26T07:09:15.983611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:16.075307Z",
     "iopub.status.busy": "2020-09-26T07:09:16.074314Z",
     "iopub.status.idle": "2020-09-26T07:09:16.081250Z",
     "shell.execute_reply": "2020-09-26T07:09:16.080461Z"
    },
    "papermill": {
     "duration": 0.037,
     "end_time": "2020-09-26T07:09:16.081387",
     "exception": false,
     "start_time": "2020-09-26T07:09:16.044387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:16.142150Z",
     "iopub.status.busy": "2020-09-26T07:09:16.141131Z",
     "iopub.status.idle": "2020-09-26T07:09:16.158563Z",
     "shell.execute_reply": "2020-09-26T07:09:16.157979Z"
    },
    "papermill": {
     "duration": 0.048852,
     "end_time": "2020-09-26T07:09:16.158682",
     "exception": false,
     "start_time": "2020-09-26T07:09:16.109830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass Name  Sex   Age  SibSp  Parch   Ticket     Fare Cabin  \\\n",
       "0          892       3   Mr    1  34.5      0      0   330911   7.8292   NaN   \n",
       "1          893       3  Mrs    0  47.0      1      0   363272   7.0000   NaN   \n",
       "2          894       2   Mr    1  62.0      0      0   240276   9.6875   NaN   \n",
       "3          895       3   Mr    1  27.0      0      0   315154   8.6625   NaN   \n",
       "4          896       3  Mrs    0  22.0      1      1  3101298  12.2875   NaN   \n",
       "\n",
       "  Embarked  \n",
       "0        Q  \n",
       "1        S  \n",
       "2        Q  \n",
       "3        S  \n",
       "4        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026686,
     "end_time": "2020-09-26T07:09:16.212608",
     "exception": false,
     "start_time": "2020-09-26T07:09:16.185922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8.Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-26T07:09:16.271684Z",
     "iopub.status.busy": "2020-09-26T07:09:16.270501Z",
     "iopub.status.idle": "2020-09-26T07:09:16.598356Z",
     "shell.execute_reply": "2020-09-26T07:09:16.597601Z"
    },
    "papermill": {
     "duration": 0.357804,
     "end_time": "2020-09-26T07:09:16.598494",
     "exception": false,
     "start_time": "2020-09-26T07:09:16.240690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'PassengerId': test_data[\"PassengerId\"].values, 'Survived':preds[\"Survived\"].values}\n",
    "\n",
    "df_submission = pd.DataFrame(data)\n",
    "\n",
    "df_submission.to_csv(\"submission_decision_tree.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030785,
     "end_time": "2020-09-26T07:09:16.658190",
     "exception": false,
     "start_time": "2020-09-26T07:09:16.627405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Final score on testing Set: 0.76076"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 37.268411,
   "end_time": "2020-09-26T07:09:16.794495",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-26T07:08:39.526084",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
